# ğŸ“¦ Base de Datos â€“ Primac  

Este repo contiene la definiciÃ³n de la **base de datos PostgreSQL**, junto con los scripts de inicializaciÃ³n (`schemas.sql`, `seed.sql`) y configuraciÃ³n de Docker para correr tanto en **entorno local** como en **AWS**.  

---

## ğŸ“‚ Estructura del repo

```
â”œâ”€â”€ init/ # Archivos de inicializaciÃ³n para PostgreSQL
â”‚ â”œâ”€â”€ schemas.sql # DefiniciÃ³n de tablas
â”‚ â”œâ”€â”€ seed.sql # Datos de ejemplo (generados con Faker)
â”‚ â””â”€â”€ generate_seed.py # Script para generar seed.sql automÃ¡ticamente
â”œâ”€â”€ Dockerfile # Imagen personalizada de Postgres (si aplica)
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ docker-compose.prod.yml
â””â”€â”€ README.md
```
---

## ğŸš€ Correr en Local

### 1ï¸âƒ£ Generar `seed.sql` (opcional)
Si quieres poblar la DB con datos falsos usando **Faker**, ejecuta:

```
python3 init/generate_seed.py
```
Esto crearÃ¡ o sobrescribirÃ¡ `init/seed.sql` con inserciones agrupadas.

### 2ï¸âƒ£ Levantar contenedor en local

Usa el ``docker-compose.dev.yml``:
```
docker compose -f docker-compose.dev.yml up -d --build
```
Esto:

- Crea un contenedor con PostgreSQL.
- Ejecuta automÃ¡ticamente los archivos de init/ (``schemas.sql`` y ``seed.sql``).

### ğŸ“Œ Para conectarte:
```
psql -h localhost -U postgres -d mydb
```
(la contraseÃ±a debe estar definida en un ``.env.dev``).

## ğŸŒ Deploy en AWS (ProducciÃ³n)
En AWS ECS / EC2 / RDS puedes usar dos enfoques:
### 1. OpciÃ³n A: DB en contenedor (ECS o EC2)
Genera seed.sql localmente:
```
python3 init/generate_seed.py
```
Sube tu imagen de DB a ECR:
```
docker build -t mydb -f Dockerfile .
docker tag mydb:latest <aws_account_id>.dkr.ecr.<region>.amazonaws.com/mydb:latest
docker push <aws_account_id>.dkr.ecr.<region>.amazonaws.com/mydb:latest
```
Configura el servicio en ECS/EC2 usando ``docker-compose.prod.yml`` o directamente en la Task Definition.

### 2. OpciÃ³n B: DB en RDS
Crea una instancia PostgreSQL en RDS.

Desde tu mÃ¡quina local o un pipeline CI/CD, corre los scripts:
```
psql -h <rds-endpoint> -U <user> -d <dbname> -f init/schemas.sql
psql -h <rds-endpoint> -U <user> -d <dbname> -f init/seed.sql
```
No necesitas contenedor en AWS, solo tu RDS + ejecuciÃ³n de scripts.

## âš™ï¸ Archivos importantes
``docker-compose.dev.yml``
```
version: "3.9"

services:
  db:
    image: postgres:15
    container_name: db_dev
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: mydb
    volumes:
      - ./init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
```

``docker-compose.prod.yml``
```
version: "3.9"

services:
  db:
    image: <aws_account_id>.dkr.ecr.<region>.amazonaws.com/mydb:latest
    container_name: db_prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
```
## ğŸ›  Tips importantes
Todo archivo dentro de ``/init/`` se ejecuta automÃ¡ticamente al crear el contenedor (solo si la DB estÃ¡ vacÃ­a).

Si corres varias veces los scripts, podrÃ­as duplicar datos â†’ por eso el seed.sql se genera limpio cada vez.

Para performance, las inserciones se agrupan en un Ãºnico ``INSERT ... VALUES (...), (...), ....``

- En local â†’ usas docker-compose.dev.yml.
- En AWS â†’ decides:
    - usar RDS y correr scripts, o
    - subir la imagen con DB inicializada a ECS/EC2.